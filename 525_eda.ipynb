{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "active-boulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import pandas as pd\n",
    "from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "heated-camcorder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sukhdeepkaur/MDS/block6/lab/aus_rain_cloud'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "prime-interference",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n",
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%load_ext rpy2.ipython\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "improving-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Necessary metadata\n",
    "article_id = 14096681  # this is the unique identifier of the article on figshare\n",
    "url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "output_directory = \"figshareairline/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "invisible-planning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'is_link_only': False,\n",
       "  'name': 'daily_rainfall_2014.png',\n",
       "  'supplied_md5': 'fd32a2ffde300a31f8d63b1825d47e5e',\n",
       "  'computed_md5': 'fd32a2ffde300a31f8d63b1825d47e5e',\n",
       "  'id': 26579150,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26579150',\n",
       "  'size': 58863},\n",
       " {'is_link_only': False,\n",
       "  'name': 'environment.yml',\n",
       "  'supplied_md5': '060b2020017eed93a1ee7dd8c65b2f34',\n",
       "  'computed_md5': '060b2020017eed93a1ee7dd8c65b2f34',\n",
       "  'id': 26579171,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26579171',\n",
       "  'size': 192},\n",
       " {'is_link_only': False,\n",
       "  'name': 'README.md',\n",
       "  'supplied_md5': '61858c6cc0e6a6d6663a7e4c75bbd88c',\n",
       "  'computed_md5': '61858c6cc0e6a6d6663a7e4c75bbd88c',\n",
       "  'id': 26586554,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26586554',\n",
       "  'size': 5422},\n",
       " {'is_link_only': False,\n",
       "  'name': 'data.zip',\n",
       "  'supplied_md5': 'b517383f76e77bd03755a63a8ff83ee9',\n",
       "  'computed_md5': 'b517383f76e77bd03755a63a8ff83ee9',\n",
       "  'id': 26766812,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26766812',\n",
       "  'size': 814041183},\n",
       " {'is_link_only': False,\n",
       "  'name': 'get_data.py',\n",
       "  'supplied_md5': '7829028495fd9dec9680ea013474afa6',\n",
       "  'computed_md5': '7829028495fd9dec9680ea013474afa6',\n",
       "  'id': 26766815,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26766815',\n",
       "  'size': 4113}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "data = json.loads(response.text)  # this contains all the articles data, feel free to check it out\n",
    "files = data[\"files\"]             # this is just the data about the files, which is what we want\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "listed-symposium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.5 s, sys: 9.35 s, total: 17.9 s\n",
      "Wall time: 13min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "files_to_dl = [\"data.zip\"]  # feel free to add other files here\n",
    "for file in files:\n",
    "    if file[\"name\"] in files_to_dl:\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        urlretrieve(file[\"download_url\"], output_directory + file[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "scheduled-response",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.9 s, sys: 3.95 s, total: 24.9 s\n",
      "Wall time: 29.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with zipfile.ZipFile(os.path.join(output_directory, \"data.zip\"), 'r') as f:\n",
    "    f.extractall(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-relaxation",
   "metadata": {},
   "source": [
    "# Step 2 - Combining the csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "blond-blind",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1692.81 MiB, increment: -69.48 MiB\n",
      "CPU times: user 6min 8s, sys: 24.8 s, total: 6min 32s\n",
      "Wall time: 6min 46s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "%memit\n",
    "\n",
    "import pandas as pd\n",
    "files = glob.glob('figshareairline/*.csv')\n",
    "df = pd.concat((pd.read_csv(file, index_col=0,)\n",
    "                .assign(model = os.path.basename(filenames).rsplit('daily')[0].replace('_', ''))\n",
    "                for file in files)\n",
    "              )\n",
    "\n",
    "df.to_csv(\"figshareairline/combined_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-going",
   "metadata": {},
   "source": [
    "machine(mac) - the CPU time : 6 min32 sec and wall time is 6 min 46s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-personality",
   "metadata": {},
   "source": [
    "# Step 3 - Loading and EDA in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-egypt",
   "metadata": {},
   "source": [
    "## EDA 1 using pandas chunksize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "sunset-enlargement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAM0-UNICON    62513863\n",
      "Name: model, dtype: int64\n",
      "peak memory: 4356.98 MiB, increment: 1848.12 MiB\n",
      "CPU times: user 1min 14s, sys: 34.6 s, total: 1min 48s\n",
      "Wall time: 2min 9s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "%%memit\n",
    "df = pd.read_csv(\"figshareairline/combined_data.csv\")\n",
    "print(df[\"model\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "hispanic-editor",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAM0-UNICON    62513863.0\n",
      "dtype: float64\n",
      "peak memory: 3048.96 MiB, increment: 416.56 MiB\n",
      "CPU times: user 1min 5s, sys: 9.11 s, total: 1min 14s\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "%%memit\n",
    "counts = pd.Series(dtype=int)\n",
    "for chunk in pd.read_csv(\"figshareairline/combined_data.csv\", chunksize=10_000_000):\n",
    "    counts = counts.add(chunk[\"model\"].value_counts(), fill_value=0)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-investment",
   "metadata": {},
   "source": [
    "In EDA1 - When chunksize is used, the memory usage is 416.56 mb, which is lower as compared to loading all the file in one time with the memory usage of 1848 mb."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-offset",
   "metadata": {},
   "source": [
    "## EDA 2 using specific columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "visible-pillow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2545.91 MiB, increment: 2401.05 MiB\n",
      "CPU times: user 59.5 s, sys: 25.9 s, total: 1min 25s\n",
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "df = pd.read_csv(\"figshareairline/combined_data.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "behind-cannon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 3126.76 MiB, increment: 1336.37 MiB\n",
      "CPU times: user 51 s, sys: 22.2 s, total: 1min 13s\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "usecols =  ['time', 'rain (mm/day)', 'model']\n",
    "#simple pandas - This is how we do normally ,which means we are loading the entire data to the memory\n",
    "df = pd.read_csv(\"figshareairline/combined_data.csv\", usecols= usecols)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-thesis",
   "metadata": {},
   "source": [
    "In second EDA, I used few columns from the combined file, hence the memory usage is 1336 mb, which is lower as compared to loading the file with all the columns with the memory usage of 2401 mb."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:525]",
   "language": "python",
   "name": "conda-env-525-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
